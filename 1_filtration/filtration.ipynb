{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Фильтрация вакансий по профессиям и размерам."
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from tqdm import tqdm"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "PROFESSIONS_PATH = \"../INPUT_DATA/professions.xlsx\"\n",
    "INPUT_FILE = \"../INPUT_DATA/hh_2023-01-01_2023-04-01.csv.bz2\"\n",
    "OUTPUT_FILE = \"resutls/filtered_vacancies.csv.gz\"\n",
    "\n",
    "CHUNKSIZE = 16\n",
    "SIM_THRESHOLD = 0.95\n",
    "MAX_RESULTS = 50\n",
    "MIN_DESC_LEN = 100\n",
    "MAX_DESC_LEN = 2000\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Использовали лёгкую модель, так как очень много данных и могли себе позволить отбросить сложные нюансы.\n",
    "model = SentenceTransformer(\"paraphrase-multilingual-MiniLM-L12-v2\", device=DEVICE)"
   ],
   "metadata": {
    "id": "tlTxkcDlEgtJ"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "prof_df = pd.read_excel(PROFESSIONS_PATH)\n",
    "professions = prof_df[\"профессия\"].dropna().astype(str).str.lower().tolist()\n",
    "profession_embeds = model.encode(professions, convert_to_tensor=True, normalize_embeddings=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "def process_chunk(chunk: pd.DataFrame) -> pd.DataFrame:\n",
    "    chunk = chunk.dropna(subset=[\"name\", \"description\"]).copy()\n",
    "    chunk[\"name_clean\"] = chunk[\"name\"].str.lower().str.strip()\n",
    "    chunk[\"desc_len\"] = chunk[\"description\"].str.len()\n",
    "\n",
    "    chunk = chunk[(chunk[\"desc_len\"] >= MIN_DESC_LEN) & (chunk[\"desc_len\"] <= MAX_DESC_LEN)].copy()\n",
    "\n",
    "    if chunk.empty:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    names = chunk[\"name_clean\"].tolist()\n",
    "    name_embeds = model.encode(names, convert_to_tensor=True, normalize_embeddings=True)\n",
    "\n",
    "    sim_matrix = util.cos_sim(name_embeds, profession_embeds)\n",
    "    max_scores, best_indices = torch.max(sim_matrix, dim=1)\n",
    "\n",
    "    chunk[\"similarity\"] = max_scores.cpu().numpy()\n",
    "    chunk[\"best_profession\"] = [professions[i] for i in best_indices]\n",
    "\n",
    "    filtered = chunk[chunk[\"similarity\"] >= SIM_THRESHOLD].copy()\n",
    "    return filtered[[\"_id\", \"name\", \"best_profession\", \"description\"]]"
   ],
   "metadata": {
    "id": "yF1uhbBDEkdU"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"Начинаем обработку\")\n",
    "reader = pd.read_csv(INPUT_FILE, compression=\"bz2\", chunksize=CHUNKSIZE, dtype={\"_id\": str})\n",
    "total_filtered = []\n",
    "total_count = 0\n",
    "\n",
    "for chunk in tqdm(reader, desc=\"Чтение чанков\"):\n",
    "    try:\n",
    "        filtered = process_chunk(chunk)\n",
    "        if not filtered.empty:\n",
    "            total_filtered.append(filtered)\n",
    "            total_count += len(filtered)\n",
    "            tqdm.write(f\"Добавлено {len(filtered)} вакансий (всего: {total_count})\")\n",
    "            if total_count >= MAX_RESULTS:\n",
    "                break\n",
    "    except Exception as e:\n",
    "        tqdm.write(f\"Ошибка в чанке: {e}\")\n",
    "        continue\n",
    "\n",
    "result_df = pd.concat(total_filtered, ignore_index=True)\n",
    "result_df.to_csv(OUTPUT_FILE, index=False, encoding=\"utf-8-sig\", compression=\"gzip\")\n",
    "print(f\"Сохранено {len(result_df)} строк в {OUTPUT_FILE}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GKTo7mW8O_Mn",
    "outputId": "1ad705d0-5557-4078-ea45-f0b57db580b7"
   },
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
