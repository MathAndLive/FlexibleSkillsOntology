### Pipeline для анализа вакансий и навыков

Этот пайплайн обрабатывает данные о вакансиях, извлекает hard/soft skills, кластеризует их и строит графы взаимосвязей.
Весь процесс состоит из 7 этапов:

---

#### 1. Фильтрация вакансий

**Файл:** `filtration.ipynb`  
**Цель:** Отобрать вакансии по профессиям из эталонного списка  
**Вход:**

- `professions.xlsx` - список профессий
- `*.csv.bz2` - сырые данные вакансий

**Процесс:**

1. Сравнивает названия вакансий с эталонными профессиями
2. Использует косинусное сходство эмбеддингов (модель `paraphrase-multilingual-MiniLM-L12-v2`)
3. Фильтрует вакансии с порогом сходства ≥0.95

**Выход:** `filtered_vacancies.csv.gz`

---

#### 2. Извлечение навыков

**Файлы:**

- `main.py` - основной скрипт
- `mistral.py` - работа с API Mistral AI
- `storage.py` - хранение результатов
- `config.py` - настройки

**Цель:** Извлечь hard/soft skills из описаний вакансий  
**Процесс:**

1. Отправляет описания вакансий в Mistral AI (модель `mistral-large-latest`)
2. Парсит ответ.
3. Сохраняет навыки в отдельные файлы:
    - `hard.txt` - технические навыки
    - `soft.txt` - мягкие навыки
    - `results.txt` - связка ID вакансии и её навыков

**Особенности:**

- Асинхронная обработка
- Ротация API-ключей
- Сохранение промежуточных результатов

---

#### 3. Объединение навыков с профессиями

**Файл:** `merge_with_profession.py`  
**Цель:** Связать извлечённые навыки с профессиями  
**Вход:**

- `filtered_vacancies.csv.gz` (из этапа 1)
- `results.txt` (из этапа 2)

**Выход:** `merged_skills.csv`

---

#### 4. Сборка финальных данных

**Файл:** `merge_data.py`  
**Цель:** Объединить результаты нескольких прогонов  
**Выход:**

- `merged_skills_final.csv` - все вакансии с навыками
- `hard_skills_final.txt` - уникальные hard skills
- `soft_skills_final.txt` - уникальные soft skills

---

#### 5. Кластеризация навыков

**Файл:** `clusterization.ipynb`  
**Цель:** Нормализовать навыки через кластеризацию  
**Процесс:**

1. Генерирует эмбеддинги (модель `ai-forever/FRIDA`)
2. Кластеризует через DBSCAN
3. Использует LLM (Gemini 2.5) для:
    - Группировки синонимов
    - Присвоения каноничных названий
4. Заменяет исходные навыки на нормализованные

**Выход:** Нормализованные CSV и TXT файлы навыков

---

#### 6. Фильтрация по эталону

**Файл:** `framework.py`  
**Цель:** Отфильтровать навыки по эталонному списку  
**Процесс:**

1. Сравнивает навыки с эталоном (`etalon.txt`)
2. Использует NPMI-сходство эмбеддингов
3. Заменяет похожие навыки на эталонные / Оставляет навыки похожие на эталонные

**Выход:** `result.csv` - финальные данные для анализа

---

#### 7. Построение графов

**Файл:** `graph.ipynb`  
**Цель:** Визуализировать связи между навыками  
**Процесс:**

1. Строит матрицу "профессия-навык"
2. Рассчитывает NPMI для пар:
    - Hard Skills ↔ Hard Skills
    - Soft Skills ↔ Soft Skills
    - Hard Skills ↔ Soft Skills
3. Визуализирует в Graphistry

**Графы:**

- Soft-Soft Skills
- Hard-Soft Skills
- Profession-Soft Skills

---

### Инструкция по запуску

1. **Установите зависимости.**

2. **Настройте API-ключи:**
    - В `config.py` укажите ключи Mistral AI
    - В `clusterization.ipynb` укажите ключ OpenAI/Gemini
    - В `graph.ipynb` укажите ключ Graphistry

3. **Порядок выполнения:**
    1. Запустите `filtration.ipynb`
    2. Запустите `main.py`
    3. Запустите `merge_with_profession.py`
    4. Запустите `merge_data.py`
    5. Выполните `clusterization.ipynb`
    6. Запустите `framework.py`
    7. Выполните `graph.ipynb`

4. **В проекте приведены все промежуточные файлы и результаты, для небольшой выборки данных.**

---

### Требования к данным

- **Вакансии:** CSV с колонками `_id`, `name`, `description`
- **Профессии:** XLSX с колонкой `профессия`
- **Эталон навыков:** TXT с одним навыком на строку

> **Важно!** Все пути к файлам настроены относительно папок проекта. Проверьте структуру папок перед запуском.

### В папке site находятся файлы для запуска сайта, подробная информация в md файле.