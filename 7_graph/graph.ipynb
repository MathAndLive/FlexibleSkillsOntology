{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "HNVdA6D4eh2f",
    "ExecuteTime": {
     "end_time": "2025-07-17T09:41:55.386570Z",
     "start_time": "2025-07-17T09:41:55.381486Z"
    }
   },
   "source": [
    "from collections import Counter"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xvkW3zoreF0s",
    "outputId": "6419e02f-1e46-461d-928e-f1e55c306e6f",
    "ExecuteTime": {
     "end_time": "2025-07-17T09:41:57.271548Z",
     "start_time": "2025-07-17T09:41:55.411782Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "from scipy.sparse import dok_matrix, save_npz\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "def build_profession_skill_matrix(csv_file_path, output_dir, chunk_size=50000):\n",
    "    \"\"\"–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –º–∞—Ç—Ä–∏—Ü—ã –ø—Ä–æ—Ñ–µ—Å—Å–∏–∏-–Ω–∞–≤—ã–∫–∏ –∏–∑ CSV —Ñ–∞–π–ª–∞\"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # 1. –ü–µ—Ä–≤—ã–π –ø—Ä–æ—Ö–æ–¥: —Å–±–æ—Ä —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π\n",
    "    unique_professions = set()\n",
    "    unique_skills = set()\n",
    "\n",
    "    print(\"üîç –ü–µ—Ä–≤—ã–π –ø—Ä–æ—Ö–æ–¥: —Å–±–æ—Ä —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø—Ä–æ—Ñ–µ—Å—Å–∏–π –∏ –Ω–∞–≤—ã–∫–æ–≤...\")\n",
    "    reader = pd.read_csv(csv_file_path,\n",
    "                        dtype={'_id': str},\n",
    "                        chunksize=chunk_size,\n",
    "                        encoding='utf-8-sig')\n",
    "\n",
    "    for chunk in tqdm(reader):\n",
    "        # –°–±–æ—Ä —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø—Ä–æ—Ñ–µ—Å—Å–∏–π —Å –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–µ–π\n",
    "        professions = chunk['best_profession'].dropna().str.strip().unique()\n",
    "        unique_professions.update(professions)\n",
    "\n",
    "        # –û–±—Ä–∞–±–æ—Ç–∫–∞ hard skills —Å –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–µ–π\n",
    "        if 'hard_skills' in chunk:\n",
    "            hard_skills = chunk['hard_skills'].dropna()\n",
    "            hard_skills = hard_skills.str.split(';').explode()\n",
    "            hard_skills = hard_skills.str.strip()\n",
    "            hard_skills = hard_skills[hard_skills != '']\n",
    "            unique_skills.update(hard_skills)\n",
    "\n",
    "        # –û–±—Ä–∞–±–æ—Ç–∫–∞ soft skills —Å –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–µ–π –∏ –ø—Ä–µ—Ñ–∏–∫—Å–æ–º\n",
    "        if 'soft_skills' in chunk:\n",
    "            soft_skills = chunk['soft_skills'].dropna()\n",
    "            soft_skills = soft_skills.str.split(';').explode()\n",
    "            soft_skills = soft_skills.str.strip()\n",
    "            soft_skills = soft_skills[soft_skills != '']\n",
    "            unique_skills.update(\"SOFT_\" + soft_skills)\n",
    "\n",
    "    # 2. –°–æ–∑–¥–∞–Ω–∏–µ —Å–ª–æ–≤–∞—Ä–µ–π –∏–Ω–¥–µ–∫—Å–æ–≤\n",
    "    profession_to_idx = {prof: idx for idx, prof in enumerate(unique_professions)}\n",
    "    skill_to_idx = {skill: idx for idx, skill in enumerate(unique_skills)}\n",
    "\n",
    "    # 3. –í—Ç–æ—Ä–æ–π –ø—Ä–æ—Ö–æ–¥: –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –º–∞—Ç—Ä–∏—Ü—ã\n",
    "    matrix = dok_matrix((len(unique_professions), len(unique_skills)), dtype=np.int32)\n",
    "\n",
    "    print(\"\\nüîß –í—Ç–æ—Ä–æ–π –ø—Ä–æ—Ö–æ–¥: –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –º–∞—Ç—Ä–∏—Ü—ã...\")\n",
    "    reader = pd.read_csv(csv_file_path,\n",
    "                        dtype={'_id': str},\n",
    "                        chunksize=chunk_size,\n",
    "                        encoding='utf-8-sig')\n",
    "\n",
    "    skipped_skills = set()\n",
    "    for chunk in tqdm(reader):\n",
    "        for _, row in chunk.iterrows():\n",
    "            if pd.isna(row['best_profession']):\n",
    "                continue\n",
    "\n",
    "            profession = str(row['best_profession']).strip()\n",
    "            if not profession or profession not in profession_to_idx:\n",
    "                continue\n",
    "\n",
    "            p_idx = profession_to_idx[profession]\n",
    "\n",
    "            # –û–±—Ä–∞–±–æ—Ç–∫–∞ hard skills\n",
    "            if pd.notna(row['hard_skills']):\n",
    "                for skill in str(row['hard_skills']).split(';'):\n",
    "                    if skill := skill.strip():\n",
    "                        if skill in skill_to_idx:\n",
    "                            s_idx = skill_to_idx[skill]\n",
    "                            matrix[p_idx, s_idx] += 1\n",
    "                        else:\n",
    "                            skipped_skills.add(skill)\n",
    "\n",
    "            # –û–±—Ä–∞–±–æ—Ç–∫–∞ soft skills\n",
    "            if pd.notna(row['soft_skills']):\n",
    "                for skill in str(row['soft_skills']).split(';'):\n",
    "                    if skill := skill.strip():\n",
    "                        skill_key = \"SOFT_\" + skill\n",
    "                        if skill_key in skill_to_idx:\n",
    "                            s_idx = skill_to_idx[skill_key]\n",
    "                            matrix[p_idx, s_idx] += 1\n",
    "                        else:\n",
    "                            skipped_skills.add(skill_key)\n",
    "\n",
    "    # –°–æ–æ–±—â–µ–Ω–∏–µ –æ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –Ω–∞–≤—ã–∫–∞—Ö\n",
    "    if skipped_skills:\n",
    "        print(f\"\\n‚ö†Ô∏è –ü—Ä–æ–ø—É—â–µ–Ω–æ {len(skipped_skills)} –Ω–∞–≤—ã–∫–æ–≤, –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏—Ö –≤ —Å–ª–æ–≤–∞—Ä–µ\")\n",
    "        print(\"–ü—Ä–∏–º–µ—Ä—ã –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –Ω–∞–≤—ã–∫–æ–≤:\", list(skipped_skills)[:5])\n",
    "\n",
    "    # 4. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n",
    "    print(\"\\nüíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤...\")\n",
    "    csr_matrix = matrix.tocsr()\n",
    "    save_npz(os.path.join(output_dir, \"profession_skills_matrix.npz\"), csr_matrix)\n",
    "\n",
    "    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å–ª–æ–≤–∞—Ä–µ–π\n",
    "    with open(os.path.join(output_dir, \"profession_to_idx.pkl\"), 'wb') as f:\n",
    "        pickle.dump(profession_to_idx, f)\n",
    "\n",
    "    with open(os.path.join(output_dir, \"skill_to_idx.pkl\"), 'wb') as f:\n",
    "        pickle.dump(skill_to_idx, f)\n",
    "\n",
    "    # –û–±—Ä–∞—Ç–Ω—ã–µ —Å–ª–æ–≤–∞—Ä–∏\n",
    "    idx_to_profession = {v: k for k, v in profession_to_idx.items()}\n",
    "    idx_to_skill = {v: k for k, v in skill_to_idx.items()}\n",
    "\n",
    "    with open(os.path.join(output_dir, \"idx_to_profession.pkl\"), 'wb') as f:\n",
    "        pickle.dump(idx_to_profession, f)\n",
    "\n",
    "    with open(os.path.join(output_dir, \"idx_to_skill.pkl\"), 'wb') as f:\n",
    "        pickle.dump(idx_to_skill, f)\n",
    "\n",
    "    print(f\"‚úÖ –ì–æ—Ç–æ–≤–æ! –ú–∞—Ç—Ä–∏—Ü–∞ —Ä–∞–∑–º–µ—Ä–æ–º {csr_matrix.shape[0]} –ø—Ä–æ—Ñ–µ—Å—Å–∏–π √ó {csr_matrix.shape[1]} –Ω–∞–≤—ã–∫–æ–≤\")\n",
    "    print(f\"üìÅ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {output_dir}\")\n",
    "\n",
    "# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è\n",
    "\n",
    "build_profession_skill_matrix(\n",
    "    csv_file_path=\"../6_framework/results/result.csv\",\n",
    "    output_dir=\"output_matrix\",\n",
    "    chunk_size=100000\n",
    ")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "üîç –ü–µ—Ä–≤—ã–π –ø—Ä–æ—Ö–æ–¥: —Å–±–æ—Ä —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø—Ä–æ—Ñ–µ—Å—Å–∏–π –∏ –Ω–∞–≤—ã–∫–æ–≤...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "1it [00:00, 151.71it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "üîß –í—Ç–æ—Ä–æ–π –ø—Ä–æ—Ö–æ–¥: –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –º–∞—Ç—Ä–∏—Ü—ã...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "1it [00:00, 49.47it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤...\n",
      "‚úÖ –ì–æ—Ç–æ–≤–æ! –ú–∞—Ç—Ä–∏—Ü–∞ —Ä–∞–∑–º–µ—Ä–æ–º 24 –ø—Ä–æ—Ñ–µ—Å—Å–∏–π √ó 345 –Ω–∞–≤—ã–∫–æ–≤\n",
      "üìÅ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: output_matrix\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9c_JClkQjShX",
    "outputId": "655ef376-062a-47b1-fd20-6714ea11617a"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting graphistry\n",
      "  Downloading graphistry-0.41.0-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from graphistry) (2.0.2)\n",
      "Collecting palettable>=3.0 (from graphistry)\n",
      "  Downloading palettable-3.3.3-py2.py3-none-any.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from graphistry) (2.2.2)\n",
      "Requirement already satisfied: pyarrow>=0.15.0 in /usr/local/lib/python3.11/dist-packages (from graphistry) (18.1.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from graphistry) (2.32.3)\n",
      "Collecting squarify (from graphistry)\n",
      "  Downloading squarify-0.4.4-py3-none-any.whl.metadata (600 bytes)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from graphistry) (4.14.1)\n",
      "Requirement already satisfied: packaging>=20.1 in /usr/local/lib/python3.11/dist-packages (from graphistry) (25.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from graphistry) (75.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->graphistry) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->graphistry) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->graphistry) (2025.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->graphistry) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->graphistry) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->graphistry) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->graphistry) (2025.7.14)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->graphistry) (1.17.0)\n",
      "Downloading graphistry-0.41.0-py3-none-any.whl (332 kB)\n",
      "\u001B[2K   \u001B[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m \u001B[32m332.4/332.4 kB\u001B[0m \u001B[31m18.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading palettable-3.3.3-py2.py3-none-any.whl (332 kB)\n",
      "\u001B[2K   \u001B[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m \u001B[32m332.3/332.3 kB\u001B[0m \u001B[31m26.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading squarify-0.4.4-py3-none-any.whl (4.1 kB)\n",
      "Installing collected packages: squarify, palettable, graphistry\n",
      "Successfully installed graphistry-0.41.0 palettable-3.3.3 squarify-0.4.4\n"
     ]
    }
   ],
   "source": [
    "!pip install graphistry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "8WiwC3nsjFv_"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import load_npz\n",
    "import pandas as pd\n",
    "import graphistry\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö\n",
    "matrix = load_npz(\"output_matrix/profession_skills_matrix.npz\")\n",
    "with open(\"output_matrix/skill_to_idx.pkl\", \"rb\") as f:\n",
    "    skill_to_idx = pickle.load(f)\n",
    "with open(\"output_matrix/idx_to_skill.pkl\", \"rb\") as f:\n",
    "    idx_to_skill = pickle.load(f)\n",
    "\n",
    "# –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ CSC –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–≥–æ –¥–æ—Å—Ç—É–ø–∞ –ø–æ —Å—Ç–æ–ª–±—Ü–∞–º (–Ω–∞–≤—ã–∫–∞–º)\n",
    "csc_matrix = matrix.tocsc()\n",
    "\n",
    "# –†–∞—Å—á–µ—Ç –æ–±—â–µ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏\n",
    "total_professions = matrix.shape[0]\n",
    "skill_frequencies = np.array(csc_matrix.sum(axis=0)).flatten()\n",
    "\n",
    "# –§—É–Ω–∫—Ü–∏—è —Ä–∞—Å—á–µ—Ç–∞ NPMI\n",
    "def calculate_npmi(skill_i, skill_j):\n",
    "    # –°–æ–≤–º–µ—Å—Ç–Ω–∞—è –≤—Å—Ç—Ä–µ—á–∞–µ–º–æ—Å—Ç—å\n",
    "    col_i = csc_matrix[:, skill_i]\n",
    "    col_j = csc_matrix[:, skill_j]\n",
    "    co_occurrence = col_i.multiply(col_j).sum()\n",
    "\n",
    "    if co_occurrence == 0:\n",
    "        return 0.0\n",
    "\n",
    "    # –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏\n",
    "    p_i = skill_frequencies[skill_i] / total_professions\n",
    "    p_j = skill_frequencies[skill_j] / total_professions\n",
    "    p_ij = co_occurrence / total_professions\n",
    "\n",
    "    # PMI –∏ NPMI\n",
    "    pmi = np.log(p_ij / (p_i * p_j))\n",
    "    npmi = pmi / (-np.log(p_ij))\n",
    "\n",
    "    return npmi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UONzGFrUmcNG",
    "outputId": "fc7c761b-59b2-427b-c3b7-5b9db6b98848"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "‚öôÔ∏è –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import math\n",
    "from scipy.sparse import load_npz\n",
    "\n",
    "# –ó–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ –≤—ã—á–∏—Å–ª–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
    "matrix = load_npz(\"output_matrix/profession_skills_matrix.npz\")\n",
    "with open(\"output_matrix/skill_to_idx.pkl\", \"rb\") as f:\n",
    "    skill_to_idx = pickle.load(f)\n",
    "with open(\"output_matrix/idx_to_skill.pkl\", \"rb\") as f:\n",
    "    idx_to_skill = pickle.load(f)\n",
    "with open(\"output_matrix/profession_to_idx.pkl\", \"rb\") as f:\n",
    "    profession_to_idx = pickle.load(f)\n",
    "\n",
    "# –í—ã—á–∏—Å–ª–µ–Ω–∏–µ —á–∞—Å—Ç–æ—Ç\n",
    "total_professions = matrix.shape[0]\n",
    "skill_frequencies = np.array(matrix.sum(axis=0)).flatten()\n",
    "profession_frequencies = np.array(matrix.sum(axis=1)).flatten()\n",
    "# –§—É–Ω–∫—Ü–∏—è —Ä–∞—Å—á–µ—Ç–∞ NPMI\n",
    "def calculate_npmi(freq_i, freq_j, co_occurrence, total):\n",
    "    if co_occurrence == 0:\n",
    "        return 0.0\n",
    "\n",
    "    p_i = freq_i / total\n",
    "    p_j = freq_j / total\n",
    "    p_ij = co_occurrence / total\n",
    "\n",
    "    # –ò–∑–±–µ–≥–∞–µ–º –Ω—É–ª–µ–≤—ã—Ö –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π\n",
    "    if p_i <= 0 or p_j <= 0 or p_ij <= 0:\n",
    "        return 0.0\n",
    "\n",
    "    pmi = math.log(p_ij / (p_i * p_j))\n",
    "    npmi = pmi / (-math.log(p_ij))\n",
    "\n",
    "    return npmi\n",
    "\n",
    "# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä –¥–∞–Ω–Ω—ã—Ö\n",
    "file_path = \"../6_framework/results/result.csv\"\n",
    "chunk_size = 100000\n",
    "min_cooccurrence = 2  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —Å–æ–≤–º–µ—Å—Ç–Ω–∞—è –≤—Å—Ç—Ä–µ—á–∞–µ–º–æ—Å—Ç—å\n",
    "\n",
    "print(\"‚öôÔ∏è –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞\")"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# –°–±–æ—Ä —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –¥–ª—è NPMI\n",
    "from itertools import combinations\n",
    "soft_soft_edges = Counter()\n",
    "soft_hard_edges = Counter()\n",
    "profession_soft_edges = Counter()\n",
    "\n",
    "soft_freq = Counter()\n",
    "hard_freq = Counter()\n",
    "profession_freq = Counter()\n",
    "total_vacancies = 0\n",
    "\n",
    "# –ü–µ—Ä–≤—ã–π –ø—Ä–æ—Ö–æ–¥: —Å–±–æ—Ä —á–∞—Å—Ç–æ—Ç\n",
    "print(\"üîç –ü–µ—Ä–≤—ã–π –ø—Ä–æ—Ö–æ–¥: —Å–±–æ—Ä —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏...\")\n",
    "reader = pd.read_csv(file_path,\n",
    "                        dtype={'_id': str},\n",
    "                        chunksize=chunk_size,\n",
    "                        encoding='utf-8-sig')\n",
    "\n",
    "\n",
    "for chunk in tqdm(reader):\n",
    "    for _, row in chunk.iterrows():\n",
    "        total_vacancies += 1\n",
    "        profession = str(row['best_profession']).strip() if pd.notna(row['best_profession']) else None\n",
    "        if profession:\n",
    "            profession_freq[profession] += 1\n",
    "\n",
    "        # Hard skills\n",
    "        hard_skills = []\n",
    "        if pd.notna(row['hard_skills']):\n",
    "            for skill in str(row['hard_skills']).split(';'):\n",
    "                if skill := skill.strip():\n",
    "                    hard_skills.append(skill)\n",
    "                    hard_freq[skill] += 1\n",
    "\n",
    "        # Soft skills\n",
    "        soft_skills = []\n",
    "        if pd.notna(row['soft_skills']):\n",
    "            for skill in str(row['soft_skills']).split(';'):\n",
    "                if skill := skill.strip():\n",
    "                    soft_skill = \"SOFT_\" + skill\n",
    "                    soft_skills.append(soft_skill)\n",
    "                    soft_freq[soft_skill] += 1\n",
    "\n",
    "        # Soft-soft —Å–≤—è–∑–∏\n",
    "        '''for i in range(len(soft_skills)):\n",
    "            for j in range(i + 1, len(soft_skills)):\n",
    "                key = tuple(sorted([soft_skills[i], soft_skills[j]]))\n",
    "                soft_soft_edges[key] += 1'''\n",
    "        for skill_pair in combinations(soft_skills, 2):\n",
    "          key = tuple(sorted(skill_pair))\n",
    "          soft_soft_edges[key] += 1\n",
    "        # Soft-hard —Å–≤—è–∑–∏\n",
    "        for soft in soft_skills:\n",
    "            for hard in hard_skills:\n",
    "                key = (soft, hard)\n",
    "                soft_hard_edges[key] += 1\n",
    "\n",
    "        # Profession-soft —Å–≤—è–∑–∏\n",
    "        if profession:\n",
    "            for soft in soft_skills:\n",
    "                key = (profession, soft)\n",
    "                profession_soft_edges[key] += 1\n",
    "\n",
    "# –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è —Ä–µ–¥–∫–∏—Ö —Å–≤—è–∑–µ–π\n",
    "soft_soft_edges = {k: v for k, v in soft_soft_edges.items() if v >= min_cooccurrence}\n",
    "soft_hard_edges = {k: v for k, v in soft_hard_edges.items() if v >= min_cooccurrence}\n",
    "profession_soft_edges = {k: v for k, v in profession_soft_edges.items() if v >= min_cooccurrence}\n",
    "\n",
    "# –†–∞—Å—á–µ—Ç NPMI –∏ —Å–æ–∑–¥–∞–Ω–∏–µ DataFrame\n",
    "def create_npmi_df(edges_dict, freq_x, freq_y):\n",
    "    rows = []\n",
    "    for (x, y), co_occur in edges_dict.items():\n",
    "        npmi = calculate_npmi(freq_x[x], freq_y[y], co_occur, total_vacancies)\n",
    "        rows.append({\n",
    "            \"source\": x,\n",
    "            \"target\": y,\n",
    "            \"co_occurrence\": co_occur,\n",
    "            \"npmi\": npmi\n",
    "        })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# –°–æ–∑–¥–∞–Ω–∏–µ DataFrame —Å NPMI\n",
    "print(\"\\nüìä –†–∞—Å—á–µ—Ç NPMI –¥–ª—è –≥—Ä–∞—Ñ–æ–≤...\")\n",
    "df_soft_soft = create_npmi_df(\n",
    "    soft_soft_edges,\n",
    "    soft_freq,\n",
    "    soft_freq\n",
    ")\n",
    "\n",
    "df_soft_hard = create_npmi_df(\n",
    "    soft_hard_edges,\n",
    "    soft_freq,\n",
    "    hard_freq\n",
    ")\n",
    "\n",
    "df_profession_soft = create_npmi_df(\n",
    "    profession_soft_edges,\n",
    "    profession_freq,\n",
    "    soft_freq\n",
    ")\n",
    "\n",
    "print(\"‚úÖ –ì—Ä–∞—Ñ—ã –ø–æ—Å—Ç—Ä–æ–µ–Ω—ã:\")\n",
    "print(f\"Soft-Soft: {len(df_soft_soft)} —Ä–µ–±–µ—Ä\")\n",
    "print(f\"Soft-Hard: {len(df_soft_hard)} —Ä–µ–±–µ—Ä\")\n",
    "print(f\"Profession-Soft: {len(df_profession_soft)} —Ä–µ–±–µ—Ä\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BTldsSiw1LRy",
    "outputId": "91eb50be-d82d-433e-be2e-f7868b397ba1"
   },
   "execution_count": 20,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "üîç –ü–µ—Ä–≤—ã–π –ø—Ä–æ—Ö–æ–¥: —Å–±–æ—Ä —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "1it [00:00, 51.39it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "üìä –†–∞—Å—á–µ—Ç NPMI –¥–ª—è –≥—Ä–∞—Ñ–æ–≤...\n",
      "‚úÖ –ì—Ä–∞—Ñ—ã –ø–æ—Å—Ç—Ä–æ–µ–Ω—ã:\n",
      "Soft-Soft: 35 —Ä–µ–±–µ—Ä\n",
      "Soft-Hard: 186 —Ä–µ–±–µ—Ä\n",
      "Profession-Soft: 19 —Ä–µ–±–µ—Ä\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    }
   ]
  },
  {
   "metadata": {
    "id": "KT4bpt7_xFZF"
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 21,
   "source": [
    "def write_to_file(soft_soft, soft_hard,profession_soft, nodes):\n",
    "    soft_soft.to_csv('df_soft_soft', encoding='utf-8')\n",
    "    print(\"–ó–∞–ø–∏—Å—å –≤ —Ñ–∞–π–ª df_soft_soft —É—Å–ø–µ—à–Ω–∞!\")\n",
    "    soft_hard.to_csv('df_soft_hard', encoding='utf-8')\n",
    "    print(\"–ó–∞–ø–∏—Å—å –≤ —Ñ–∞–π–ª df_soft_hard —É—Å–ø–µ—à–Ω–∞!\")\n",
    "    profession_soft.to_csv('df_profession_soft',encoding='utf-8')\n",
    "    print(\"–ó–∞–ø–∏—Å—å –≤ —Ñ–∞–π–ª df_profession_soft —É—Å–ø–µ—à–Ω–∞!\")\n",
    "    nodes.to_csv('df_nodes',encoding='utf-8')\n",
    "    print(\"–ó–∞–ø–∏—Å—å –≤ —Ñ–∞–π–ª df_nodes —É—Å–ø–µ—à–Ω–∞!\")"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "number_of_edges=100"
   ],
   "metadata": {
    "id": "ES1hDazIU32D"
   },
   "execution_count": 22,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "graphistry.register(api=3, protocol=\"https\", server=\"hub.graphistry.com\",\n",
    "                    personal_key_id=\"–í–ê–®_KEY_ID\", personal_key_secret=\"–í–ê–©_KEY_SECRET\")"
   ],
   "metadata": {
    "id": "i4GL16gcPm7P",
    "outputId": "54f8ffa9-c062-46e6-be31-d56a75a1bd4d",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "execution_count": 26,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<graphistry.pygraphistry.GraphistryClient at 0x7db3c9e76490>"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö\n",
    "nodes_set = set(df_soft_soft['source']).union(set(df_soft_soft['target']))\n",
    "nodes_df = pd.DataFrame({\"node\": list(nodes_set)})\n",
    "nodes_df[\"frequency\"] = nodes_df[\"node\"].map(soft_freq)\n",
    "nodes_df[\"type\"] = \"soft\"\n",
    "\n",
    "# –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è —Å–ª–∞–±—ã—Ö —Å–≤—è–∑–µ–π\n",
    "filtered_edges = df_soft_soft[df_soft_soft[\"npmi\"] > 0.2] \\\n",
    "    .sort_values(\"npmi\", ascending=False) \\\n",
    "    .head(number_of_edges)\n",
    "\n",
    "top_nodes = set(filtered_edges['source']).union(set(filtered_edges['target']))\n",
    "nodes_df = nodes_df[nodes_df['node'].isin(top_nodes)]\n",
    "\n",
    "# –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∞\n",
    "g = graphistry.nodes(nodes_df, \"node\") \\\n",
    "    .edges(filtered_edges, \"source\", \"target\") \\\n",
    "    .bind(\n",
    "        #point_color=\"type\",\n",
    "        point_size=\"frequency\",\n",
    "        edge_weight=\"npmi\",\n",
    "        edge_title=\"co_occurrence\"\n",
    "    )\n",
    "print(\"–í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–Ø Soft-Soft –≥—Ä–∞—Ñ–∞ –ø–æ –¢–û–ü-\"+str(number_of_edges)+ \" —Å–≤—è–∑—è–º –ø–æ NPMI\")\n",
    "\n",
    "g.plot()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 561
    },
    "id": "Ifo_BPfTT5RX",
    "outputId": "681a8148-712f-4c5c-f077-8630f2af3594"
   },
   "execution_count": 27,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "–í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–Ø Soft-Soft –≥—Ä–∞—Ñ–∞ –ø–æ –¢–û–ü-100 —Å–≤—è–∑—è–º –ø–æ NPMI\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "            <iframe id=\"a36ff010-a88e-4cf7-a037-66e2516d3b2f\" src=\"https://hub.graphistry.com/graph/graph.html?dataset=67f658811a6a4c159f713c216750d872&type=arrow&viztoken=19a90907-98ed-4743-8157-c32f97826234&usertag=dcb3cafb-pygraphistry-0.41.0&splashAfter=1753793762&info=true\"\n",
       "                    allowfullscreen=\"true\" webkitallowfullscreen=\"true\" mozallowfullscreen=\"true\"\n",
       "                    oallowfullscreen=\"true\" msallowfullscreen=\"true\"\n",
       "                    style=\"width:100%; height:500px; border: 1px solid #DDD; overflow: hidden\"\n",
       "                    \n",
       "            >\n",
       "            </iframe>\n",
       "        \n",
       "            <script>\n",
       "                try {\n",
       "                  $(\"#a36ff010-a88e-4cf7-a037-66e2516d3b2f\").bind('mousewheel', function(e) { e.preventDefault(); });\n",
       "                } catch (e) { console.error('exn catching scroll', e); }\n",
       "            </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö\n",
    "nodes_set = set(df_soft_hard['source']).union(set(df_soft_hard['target']))\n",
    "nodes_df = pd.DataFrame({\"node\": list(nodes_set)})\n",
    "\n",
    "# –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–∞ —É–∑–ª–∞ –∏ —á–∞—Å—Ç–æ—Ç—ã\n",
    "def get_node_type(node):\n",
    "    if node.startswith(\"SOFT_\"):\n",
    "        return \"soft\", soft_freq.get(node, 1)\n",
    "    return \"hard\", hard_freq.get(node, 1)\n",
    "\n",
    "nodes_df[[\"type\", \"frequency\"]] = nodes_df[\"node\"].apply(\n",
    "    lambda x: pd.Series(get_node_type(x))\n",
    ")\n",
    "\n",
    "# –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è —Å–≤—è–∑–µ–π\n",
    "filtered_edges = df_soft_hard[df_soft_hard[\"npmi\"] > 0.2] \\\n",
    "    .sort_values(\"npmi\", ascending=False) \\\n",
    "    .head(number_of_edges)\n",
    "\n",
    "top_nodes = set(filtered_edges['source']).union(set(filtered_edges['target']))\n",
    "nodes_df = nodes_df[nodes_df['node'].isin(top_nodes)]\n",
    "\n",
    "# –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∞\n",
    "g = graphistry.nodes(nodes_df, \"node\") \\\n",
    "    .edges(filtered_edges, \"source\", \"target\") \\\n",
    "    .bind(\n",
    "        point_color=\"type\",\n",
    "        point_size=\"frequency\",\n",
    "        point_title=\"node\",\n",
    "        edge_weight=\"npmi\",\n",
    "        edge_title=\"co_occurrence\"\n",
    "    )\\\n",
    "    .encode_point_color(\"type\", categorical_mapping={\n",
    "          'soft': 'blue',\n",
    "          'hard': 'orange'\n",
    "      }, default_mapping='gray')\n",
    "\n",
    "\n",
    "print(\"–í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–Ø Soft-Hard –≥—Ä–∞—Ñ–∞ –ø–æ –¢–û–ü-\"+str(number_of_edges)+ \" —Å–≤—è–∑—è–º –ø–æ NPMI\")\n",
    "g.plot()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 561
    },
    "id": "zkhqXV_TW27p",
    "outputId": "d26bbf8f-2e18-4dad-9ece-c4d3453fcaf2"
   },
   "execution_count": 28,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "–í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–Ø Soft-Hard –≥—Ä–∞—Ñ–∞ –ø–æ –¢–û–ü-100 —Å–≤—è–∑—è–º –ø–æ NPMI\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "            <iframe id=\"09bf6c0f-588e-4699-aa78-1bcb9ba52515\" src=\"https://hub.graphistry.com/graph/graph.html?dataset=b3d217ebf7c5494d8a25d2a2b5cd545e&type=arrow&viztoken=71481f1d-9e71-4c11-af19-e50d31068fe3&usertag=dcb3cafb-pygraphistry-0.41.0&splashAfter=1753793804&info=true\"\n",
       "                    allowfullscreen=\"true\" webkitallowfullscreen=\"true\" mozallowfullscreen=\"true\"\n",
       "                    oallowfullscreen=\"true\" msallowfullscreen=\"true\"\n",
       "                    style=\"width:100%; height:500px; border: 1px solid #DDD; overflow: hidden\"\n",
       "                    \n",
       "            >\n",
       "            </iframe>\n",
       "        \n",
       "            <script>\n",
       "                try {\n",
       "                  $(\"#09bf6c0f-588e-4699-aa78-1bcb9ba52515\").bind('mousewheel', function(e) { e.preventDefault(); });\n",
       "                } catch (e) { console.error('exn catching scroll', e); }\n",
       "            </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö\n",
    "nodes_set = set(df_profession_soft['source']).union(set(df_profession_soft['target']))\n",
    "nodes_df = pd.DataFrame({\"node\": list(nodes_set)})\n",
    "\n",
    "# –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–∞ —É–∑–ª–∞ –∏ —á–∞—Å—Ç–æ—Ç—ã\n",
    "def get_node_type(node):\n",
    "    if node in profession_freq:\n",
    "        return \"profession\", profession_freq.get(node, 1)\n",
    "    return \"soft\", soft_freq.get(node, 1)\n",
    "\n",
    "nodes_df[[\"type\", \"frequency\"]] = nodes_df[\"node\"].apply(\n",
    "    lambda x: pd.Series(get_node_type(x))\n",
    ")\n",
    "\n",
    "# –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è —Å–≤—è–∑–µ–π\n",
    "#filtered_edges = df_profession_soft[df_profession_soft[\"npmi\"] > 0.05]\n",
    "filtered_edges = df_profession_soft[df_profession_soft[\"npmi\"] > 0.2] \\\n",
    "    .sort_values(\"npmi\", ascending=False) \\\n",
    "    .head(number_of_edges)\n",
    "\n",
    "top_nodes = set(filtered_edges['source']).union(set(filtered_edges['target']))\n",
    "nodes_df = nodes_df[nodes_df['node'].isin(top_nodes)]\n",
    "# –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∞\n",
    "g = graphistry.nodes(nodes_df, \"node\") \\\n",
    "    .edges(filtered_edges, \"source\", \"target\") \\\n",
    "    .bind(\n",
    "        point_color=\"type\",\n",
    "        point_size=\"frequency\",\n",
    "        point_title=\"node\",\n",
    "        edge_weight=\"npmi\",\n",
    "        edge_title=\"co_occurrence\"\n",
    "    )\\\n",
    "    .encode_point_color(\"type\", categorical_mapping={\n",
    "          'profession': 'red',\n",
    "          'soft': 'blue'\n",
    "      }, default_mapping='gray')\n",
    "\n",
    "\n",
    "print(\"–í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–Ø Profession-Soft –≥—Ä–∞—Ñ–∞ –ø–æ –¢–û–ü-\"+str(number_of_edges)+ \" —Å–≤—è–∑—è–º –ø–æ NPMI\")\n",
    "g.plot()"
   ],
   "metadata": {
    "id": "9S9-I54b1Lnm",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 561
    },
    "outputId": "9bf70b17-8fde-4876-d941-ba34b48e532a"
   },
   "execution_count": 29,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "–í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–Ø Profession-Soft –≥—Ä–∞—Ñ–∞ –ø–æ –¢–û–ü-100 —Å–≤—è–∑—è–º –ø–æ NPMI\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "            <iframe id=\"91ce8892-43a3-40a6-b69d-65335872f1e4\" src=\"https://hub.graphistry.com/graph/graph.html?dataset=d3f8b039feca4943942a123bc3839fba&type=arrow&viztoken=609cad4d-3002-4741-a630-e002d824aaa9&usertag=dcb3cafb-pygraphistry-0.41.0&splashAfter=1753793807&info=true\"\n",
       "                    allowfullscreen=\"true\" webkitallowfullscreen=\"true\" mozallowfullscreen=\"true\"\n",
       "                    oallowfullscreen=\"true\" msallowfullscreen=\"true\"\n",
       "                    style=\"width:100%; height:500px; border: 1px solid #DDD; overflow: hidden\"\n",
       "                    \n",
       "            >\n",
       "            </iframe>\n",
       "        \n",
       "            <script>\n",
       "                try {\n",
       "                  $(\"#91ce8892-43a3-40a6-b69d-65335872f1e4\").bind('mousewheel', function(e) { e.preventDefault(); });\n",
       "                } catch (e) { console.error('exn catching scroll', e); }\n",
       "            </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
