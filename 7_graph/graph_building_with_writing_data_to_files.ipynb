{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNVdA6D4eh2f",
        "ExecuteTime": {
          "end_time": "2025-07-17T09:41:55.386570Z",
          "start_time": "2025-07-17T09:41:55.381486Z"
        }
      },
      "source": [
        "from collections import Counter"
      ],
      "outputs": [],
      "execution_count": 1
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xvkW3zoreF0s",
        "outputId": "c1da3cb5-112a-46c5-ce87-989c3028899d",
        "ExecuteTime": {
          "end_time": "2025-07-17T09:41:57.271548Z",
          "start_time": "2025-07-17T09:41:55.411782Z"
        }
      },
      "source": [
        "import pandas as pd\n",
        "from scipy.sparse import dok_matrix, save_npz\n",
        "import numpy as np\n",
        "import pickle\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "\n",
        "def build_profession_skill_matrix(file_path, output_dir, chunk_size=50000):\n",
        "    \"\"\"–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –º–∞—Ç—Ä–∏—Ü—ã –ø—Ä–æ—Ñ–µ—Å—Å–∏–∏-–Ω–∞–≤—ã–∫–∏ –¥–ª—è –±–æ–ª—å—à–∏—Ö —Ñ–∞–π–ª–æ–≤\"\"\"\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # 1. –ü–µ—Ä–≤—ã–π –ø—Ä–æ—Ö–æ–¥: —Å–±–æ—Ä —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π\n",
        "    unique_professions = set()\n",
        "    unique_skills = set()\n",
        "\n",
        "    print(\"üîç –ü–µ—Ä–≤—ã–π –ø—Ä–æ—Ö–æ–¥: —Å–±–æ—Ä —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø—Ä–æ—Ñ–µ—Å—Å–∏–π –∏ –Ω–∞–≤—ã–∫–æ–≤...\")\n",
        "    reader = pd.read_csv(file_path, sep='|', header=None,\n",
        "                         names=['id','profession', 'hard_skills', 'soft_skills'],\n",
        "                         chunksize=chunk_size, low_memory=False)\n",
        "\n",
        "    for chunk in tqdm(reader):\n",
        "        # –°–±–æ—Ä —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø—Ä–æ—Ñ–µ—Å—Å–∏–π —Å –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–µ–π\n",
        "        professions = chunk['profession'].dropna().str.strip().unique()\n",
        "        unique_professions.update(professions)\n",
        "\n",
        "        # –û–±—Ä–∞–±–æ—Ç–∫–∞ hard skills —Å –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–µ–π\n",
        "        if 'hard_skills' in chunk:\n",
        "            hard_skills = chunk['hard_skills'].dropna()\n",
        "            hard_skills = hard_skills.str.split(';').explode()\n",
        "            hard_skills = hard_skills.str.strip()  # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è\n",
        "            hard_skills = hard_skills[hard_skills != '']\n",
        "            unique_skills.update(hard_skills)\n",
        "\n",
        "        # –û–±—Ä–∞–±–æ—Ç–∫–∞ soft skills —Å –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–µ–π –∏ –ø—Ä–µ—Ñ–∏–∫—Å–æ–º\n",
        "        if 'soft_skills' in chunk:\n",
        "            soft_skills = chunk['soft_skills'].dropna()\n",
        "            soft_skills = soft_skills.str.split(';').explode()\n",
        "            soft_skills = soft_skills.str.strip()  # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è\n",
        "            soft_skills = soft_skills[soft_skills != '']\n",
        "            unique_skills.update(\"SOFT_\" + soft_skills)\n",
        "\n",
        "    # 2. –°–æ–∑–¥–∞–Ω–∏–µ —Å–ª–æ–≤–∞—Ä–µ–π –∏–Ω–¥–µ–∫—Å–æ–≤\n",
        "    profession_to_idx = {prof: idx for idx, prof in enumerate(unique_professions)}\n",
        "    skill_to_idx = {skill: idx for idx, skill in enumerate(unique_skills)}\n",
        "\n",
        "    # 3. –í—Ç–æ—Ä–æ–π –ø—Ä–æ—Ö–æ–¥: –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –º–∞—Ç—Ä–∏—Ü—ã\n",
        "    matrix = dok_matrix((len(unique_professions), len(unique_skills)), dtype=np.int32)\n",
        "\n",
        "    print(\"\\nüîß –í—Ç–æ—Ä–æ–π –ø—Ä–æ—Ö–æ–¥: –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –º–∞—Ç—Ä–∏—Ü—ã...\")\n",
        "    reader = pd.read_csv(file_path, sep='|', header=None,\n",
        "                         names=['profession', 'hard_skills', 'soft_skills'],\n",
        "                         chunksize=chunk_size, low_memory=False)\n",
        "\n",
        "    skipped_skills = set()  # –î–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –Ω–∞–≤—ã–∫–æ–≤\n",
        "    for chunk in tqdm(reader):\n",
        "        for _, row in chunk.iterrows():\n",
        "            if pd.isna(row['profession']):\n",
        "                continue\n",
        "\n",
        "            # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ—Ñ–µ—Å—Å–∏–∏\n",
        "            profession = str(row['profession']).strip()\n",
        "            if not profession or profession not in profession_to_idx:\n",
        "                continue\n",
        "\n",
        "            p_idx = profession_to_idx[profession]\n",
        "\n",
        "            # –û–±—Ä–∞–±–æ—Ç–∫–∞ hard skills —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π\n",
        "            if pd.notna(row['hard_skills']):\n",
        "                for skill in str(row['hard_skills']).split(';'):\n",
        "                    if skill := skill.strip():\n",
        "                        if skill in skill_to_idx:\n",
        "                            s_idx = skill_to_idx[skill]\n",
        "                            matrix[p_idx, s_idx] += 1\n",
        "                        else:\n",
        "                            skipped_skills.add(skill)\n",
        "\n",
        "            # –û–±—Ä–∞–±–æ—Ç–∫–∞ soft skills —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π\n",
        "            if pd.notna(row['soft_skills']):\n",
        "                for skill in str(row['soft_skills']).split(';'):\n",
        "                    if skill := skill.strip():\n",
        "                        skill_key = \"SOFT_\" + skill\n",
        "                        if skill_key in skill_to_idx:\n",
        "                            s_idx = skill_to_idx[skill_key]\n",
        "                            matrix[p_idx, s_idx] += 1\n",
        "                        else:\n",
        "                            skipped_skills.add(skill_key)\n",
        "\n",
        "    # –°–æ–æ–±—â–∞–µ–º –æ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –Ω–∞–≤—ã–∫–∞—Ö\n",
        "    if skipped_skills:\n",
        "        print(f\"\\n‚ö†Ô∏è –ü—Ä–æ–ø—É—â–µ–Ω–æ {len(skipped_skills)} –Ω–∞–≤—ã–∫–æ–≤, –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏—Ö –≤ —Å–ª–æ–≤–∞—Ä–µ\")\n",
        "        print(\"–ü—Ä–∏–º–µ—Ä—ã –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –Ω–∞–≤—ã–∫–æ–≤:\", list(skipped_skills)[:5])\n",
        "\n",
        "    # 4. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n",
        "    print(\"\\nüíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤...\")\n",
        "    # –ú–∞—Ç—Ä–∏—Ü–∞ –≤ CSR —Ñ–æ—Ä–º–∞—Ç–µ\n",
        "    csr_matrix = matrix.tocsr()\n",
        "    save_npz(os.path.join(output_dir, \"profession_skills_matrix.npz\"), csr_matrix)\n",
        "\n",
        "    # –°–ª–æ–≤–∞—Ä–∏ –∏–Ω–¥–µ–∫—Å–æ–≤\n",
        "    with open(os.path.join(output_dir, \"profession_to_idx.pkl\"), 'wb') as f:\n",
        "        pickle.dump(profession_to_idx, f)\n",
        "\n",
        "    with open(os.path.join(output_dir, \"skill_to_idx.pkl\"), 'wb') as f:\n",
        "        pickle.dump(skill_to_idx, f)\n",
        "\n",
        "    # –û–±—Ä–∞—Ç–Ω—ã–µ –∏–Ω–¥–µ–∫—Å—ã\n",
        "    idx_to_profession = {v: k for k, v in profession_to_idx.items()}\n",
        "    idx_to_skill = {v: k for k, v in skill_to_idx.items()}\n",
        "\n",
        "    with open(os.path.join(output_dir, \"idx_to_profession.pkl\"), 'wb') as f:\n",
        "        pickle.dump(idx_to_profession, f)\n",
        "\n",
        "    with open(os.path.join(output_dir, \"idx_to_skill.pkl\"), 'wb') as f:\n",
        "        pickle.dump(idx_to_skill, f)\n",
        "\n",
        "    print(f\"‚úÖ –ì–æ—Ç–æ–≤–æ! –ú–∞—Ç—Ä–∏—Ü–∞ —Ä–∞–∑–º–µ—Ä–æ–º {csr_matrix.shape[0]} –ø—Ä–æ—Ñ–µ—Å—Å–∏–π √ó {csr_matrix.shape[1]} –Ω–∞–≤—ã–∫–æ–≤\")\n",
        "    print(f\"üìÅ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {output_dir}\")\n",
        "\n",
        "# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è\n",
        "if __name__ == \"__main__\":\n",
        "    build_profession_skill_matrix(\n",
        "        file_path=\"/data/extracted_skills11.txt\",\n",
        "        output_dir=\"output_matrix\",\n",
        "        chunk_size=100000  # –†–∞–∑–º–µ—Ä —á–∞–Ω–∫–∞ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏\n",
        "    )"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîç –ü–µ—Ä–≤—ã–π –ø—Ä–æ—Ö–æ–¥: —Å–±–æ—Ä —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø—Ä–æ—Ñ–µ—Å—Å–∏–π –∏ –Ω–∞–≤—ã–∫–æ–≤...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1it [00:01,  1.37s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîß –í—Ç–æ—Ä–æ–π –ø—Ä–æ—Ö–æ–¥: –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –º–∞—Ç—Ä–∏—Ü—ã...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1it [00:20, 20.78s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤...\n",
            "‚úÖ –ì–æ—Ç–æ–≤–æ! –ú–∞—Ç—Ä–∏—Ü–∞ —Ä–∞–∑–º–µ—Ä–æ–º 91 –ø—Ä–æ—Ñ–µ—Å—Å–∏–π √ó 118120 –Ω–∞–≤—ã–∫–æ–≤\n",
            "üìÅ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: output_matrix\n"
          ]
        }
      ],
      "execution_count": 2
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9c_JClkQjShX",
        "outputId": "b4f556dc-82c8-4230-cd8d-fe9cf41f1110"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting graphistry\n",
            "  Downloading graphistry-0.41.0-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from graphistry) (2.0.2)\n",
            "Collecting palettable>=3.0 (from graphistry)\n",
            "  Downloading palettable-3.3.3-py2.py3-none-any.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from graphistry) (2.2.2)\n",
            "Requirement already satisfied: pyarrow>=0.15.0 in /usr/local/lib/python3.11/dist-packages (from graphistry) (18.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from graphistry) (2.32.3)\n",
            "Collecting squarify (from graphistry)\n",
            "  Downloading squarify-0.4.4-py3-none-any.whl.metadata (600 bytes)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from graphistry) (4.14.1)\n",
            "Requirement already satisfied: packaging>=20.1 in /usr/local/lib/python3.11/dist-packages (from graphistry) (25.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from graphistry) (75.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->graphistry) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->graphistry) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->graphistry) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->graphistry) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->graphistry) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->graphistry) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->graphistry) (2025.7.14)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->graphistry) (1.17.0)\n",
            "Downloading graphistry-0.41.0-py3-none-any.whl (332 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m332.4/332.4 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading palettable-3.3.3-py2.py3-none-any.whl (332 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m332.3/332.3 kB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading squarify-0.4.4-py3-none-any.whl (4.1 kB)\n",
            "Installing collected packages: squarify, palettable, graphistry\n",
            "Successfully installed graphistry-0.41.0 palettable-3.3.3 squarify-0.4.4\n"
          ]
        }
      ],
      "source": [
        "!pip install graphistry"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "8WiwC3nsjFv_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3379cd18-2563-4d32-c24a-de62b8a577da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/cudf/utils/gpu_utils.py:75: UserWarning: Failed to dlopen libcuda.so.1\n",
            "  warnings.warn(str(e))\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from scipy.sparse import load_npz\n",
        "import pandas as pd\n",
        "import graphistry\n",
        "import pickle\n",
        "from tqdm import tqdm\n",
        "\n",
        "# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö\n",
        "matrix = load_npz(\"output_matrix/profession_skills_matrix.npz\")\n",
        "with open(\"output_matrix/skill_to_idx.pkl\", \"rb\") as f:\n",
        "    skill_to_idx = pickle.load(f)\n",
        "with open(\"output_matrix/idx_to_skill.pkl\", \"rb\") as f:\n",
        "    idx_to_skill = pickle.load(f)\n",
        "\n",
        "# –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ CSC –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–≥–æ –¥–æ—Å—Ç—É–ø–∞ –ø–æ —Å—Ç–æ–ª–±—Ü–∞–º (–Ω–∞–≤—ã–∫–∞–º)\n",
        "csc_matrix = matrix.tocsc()\n",
        "\n",
        "# –†–∞—Å—á–µ—Ç –æ–±—â–µ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏\n",
        "total_professions = matrix.shape[0]\n",
        "skill_frequencies = np.array(csc_matrix.sum(axis=0)).flatten()\n",
        "\n",
        "# –§—É–Ω–∫—Ü–∏—è —Ä–∞—Å—á–µ—Ç–∞ NPMI\n",
        "def calculate_npmi(skill_i, skill_j):\n",
        "    # –°–æ–≤–º–µ—Å—Ç–Ω–∞—è –≤—Å—Ç—Ä–µ—á–∞–µ–º–æ—Å—Ç—å\n",
        "    col_i = csc_matrix[:, skill_i]\n",
        "    col_j = csc_matrix[:, skill_j]\n",
        "    co_occurrence = col_i.multiply(col_j).sum()\n",
        "\n",
        "    if co_occurrence == 0:\n",
        "        return 0.0\n",
        "\n",
        "    # –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏\n",
        "    p_i = skill_frequencies[skill_i] / total_professions\n",
        "    p_j = skill_frequencies[skill_j] / total_professions\n",
        "    p_ij = co_occurrence / total_professions\n",
        "\n",
        "    # PMI –∏ NPMI\n",
        "    pmi = np.log(p_ij / (p_i * p_j))\n",
        "    npmi = pmi / (-np.log(p_ij))\n",
        "\n",
        "    return npmi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UONzGFrUmcNG",
        "outputId": "f0e73863-46bc-4a99-ad9f-9436c35bb4e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚öôÔ∏è –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "import pickle\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import math\n",
        "from scipy.sparse import load_npz\n",
        "\n",
        "# –ó–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ –≤—ã—á–∏—Å–ª–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
        "matrix = load_npz(\"output_matrix/profession_skills_matrix.npz\")\n",
        "with open(\"output_matrix/skill_to_idx.pkl\", \"rb\") as f:\n",
        "    skill_to_idx = pickle.load(f)\n",
        "with open(\"output_matrix/idx_to_skill.pkl\", \"rb\") as f:\n",
        "    idx_to_skill = pickle.load(f)\n",
        "with open(\"output_matrix/profession_to_idx.pkl\", \"rb\") as f:\n",
        "    profession_to_idx = pickle.load(f)\n",
        "\n",
        "# –í—ã—á–∏—Å–ª–µ–Ω–∏–µ —á–∞—Å—Ç–æ—Ç\n",
        "total_professions = matrix.shape[0]\n",
        "skill_frequencies = np.array(matrix.sum(axis=0)).flatten()\n",
        "profession_frequencies = np.array(matrix.sum(axis=1)).flatten()\n",
        "# –§—É–Ω–∫—Ü–∏—è —Ä–∞—Å—á–µ—Ç–∞ NPMI\n",
        "def calculate_npmi(freq_i, freq_j, co_occurrence, total):\n",
        "    if co_occurrence == 0:\n",
        "        return 0.0\n",
        "\n",
        "    p_i = freq_i / total\n",
        "    p_j = freq_j / total\n",
        "    p_ij = co_occurrence / total\n",
        "\n",
        "    # –ò–∑–±–µ–≥–∞–µ–º –Ω—É–ª–µ–≤—ã—Ö –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π\n",
        "    if p_i <= 0 or p_j <= 0 or p_ij <= 0:\n",
        "        return 0.0\n",
        "\n",
        "    pmi = math.log(p_ij / (p_i * p_j))\n",
        "    npmi = pmi / (-math.log(p_ij))\n",
        "\n",
        "    return npmi\n",
        "\n",
        "# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä –¥–∞–Ω–Ω—ã—Ö\n",
        "file_path = \"/data/extracted_skills11.txt\"\n",
        "chunk_size = 100000\n",
        "min_cooccurrence = 10  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —Å–æ–≤–º–µ—Å—Ç–Ω–∞—è –≤—Å—Ç—Ä–µ—á–∞–µ–º–æ—Å—Ç—å\n",
        "\n",
        "print(\"‚öôÔ∏è –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# –°–±–æ—Ä —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –¥–ª—è NPMI\n",
        "from itertools import combinations\n",
        "soft_soft_edges = Counter()\n",
        "soft_hard_edges = Counter()\n",
        "profession_soft_edges = Counter()\n",
        "\n",
        "soft_freq = Counter()\n",
        "hard_freq = Counter()\n",
        "profession_freq = Counter()\n",
        "total_vacancies = 0\n",
        "\n",
        "# –ü–µ—Ä–≤—ã–π –ø—Ä–æ—Ö–æ–¥: —Å–±–æ—Ä —á–∞—Å—Ç–æ—Ç\n",
        "print(\"üîç –ü–µ—Ä–≤—ã–π –ø—Ä–æ—Ö–æ–¥: —Å–±–æ—Ä —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏...\")\n",
        "reader = pd.read_csv(\n",
        "    file_path,\n",
        "    sep='|',\n",
        "    header=None,\n",
        "    names=['id', 'profession', 'hard_skills', 'soft_skills'],\n",
        "    chunksize=chunk_size,\n",
        "    low_memory=False\n",
        ")\n",
        "\n",
        "for chunk in tqdm(reader):\n",
        "    for _, row in chunk.iterrows():\n",
        "        total_vacancies += 1\n",
        "\n",
        "        profession = str(row['profession']).strip() if pd.notna(row['profession']) else None\n",
        "        if profession:\n",
        "            profession_freq[profession] += 1\n",
        "\n",
        "        # Hard skills\n",
        "        hard_skills = []\n",
        "        if pd.notna(row['hard_skills']):\n",
        "            for skill in str(row['hard_skills']).split(';'):\n",
        "                if skill := skill.strip():\n",
        "                    hard_skills.append(skill)\n",
        "                    hard_freq[skill] += 1\n",
        "\n",
        "        # Soft skills\n",
        "        soft_skills = []\n",
        "        if pd.notna(row['soft_skills']):\n",
        "            for skill in str(row['soft_skills']).split(';'):\n",
        "                if skill := skill.strip():\n",
        "                    soft_skill = \"SOFT_\" + skill\n",
        "                    soft_skills.append(soft_skill)\n",
        "                    soft_freq[soft_skill] += 1\n",
        "\n",
        "        # Soft-soft —Å–≤—è–∑–∏\n",
        "        '''for i in range(len(soft_skills)):\n",
        "            for j in range(i + 1, len(soft_skills)):\n",
        "                key = tuple(sorted([soft_skills[i], soft_skills[j]]))\n",
        "                soft_soft_edges[key] += 1'''\n",
        "        for skill_pair in combinations(soft_skills, 2):\n",
        "          key = tuple(sorted(skill_pair))\n",
        "          soft_soft_edges[key] += 1\n",
        "        # Soft-hard —Å–≤—è–∑–∏\n",
        "        for soft in soft_skills:\n",
        "            for hard in hard_skills:\n",
        "                key = (soft, hard)\n",
        "                soft_hard_edges[key] += 1\n",
        "\n",
        "        # Profession-soft —Å–≤—è–∑–∏\n",
        "        if profession:\n",
        "            for soft in soft_skills:\n",
        "                key = (profession, soft)\n",
        "                profession_soft_edges[key] += 1\n",
        "\n",
        "# –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è —Ä–µ–¥–∫–∏—Ö —Å–≤—è–∑–µ–π\n",
        "soft_soft_edges = {k: v for k, v in soft_soft_edges.items() if v >= min_cooccurrence}\n",
        "soft_hard_edges = {k: v for k, v in soft_hard_edges.items() if v >= min_cooccurrence}\n",
        "profession_soft_edges = {k: v for k, v in profession_soft_edges.items() if v >= min_cooccurrence}\n",
        "\n",
        "# –†–∞—Å—á–µ—Ç NPMI –∏ —Å–æ–∑–¥–∞–Ω–∏–µ DataFrame\n",
        "def create_npmi_df(edges_dict, freq_x, freq_y):\n",
        "    rows = []\n",
        "    for (x, y), co_occur in edges_dict.items():\n",
        "        npmi = calculate_npmi(freq_x[x], freq_y[y], co_occur, total_vacancies)\n",
        "        rows.append({\n",
        "            \"source\": x,\n",
        "            \"target\": y,\n",
        "            \"co_occurrence\": co_occur,\n",
        "            \"npmi\": npmi\n",
        "        })\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "# –°–æ–∑–¥–∞–Ω–∏–µ DataFrame —Å NPMI\n",
        "print(\"\\nüìä –†–∞—Å—á–µ—Ç NPMI –¥–ª—è –≥—Ä–∞—Ñ–æ–≤...\")\n",
        "df_soft_soft = create_npmi_df(\n",
        "    soft_soft_edges,\n",
        "    soft_freq,\n",
        "    soft_freq\n",
        ")\n",
        "\n",
        "df_soft_hard = create_npmi_df(\n",
        "    soft_hard_edges,\n",
        "    soft_freq,\n",
        "    hard_freq\n",
        ")\n",
        "\n",
        "df_profession_soft = create_npmi_df(\n",
        "    profession_soft_edges,\n",
        "    profession_freq,\n",
        "    soft_freq\n",
        ")\n",
        "\n",
        "print(\"‚úÖ –ì—Ä–∞—Ñ—ã –ø–æ—Å—Ç—Ä–æ–µ–Ω—ã:\")\n",
        "print(f\"Soft-Soft: {len(df_soft_soft)} —Ä–µ–±–µ—Ä\")\n",
        "print(f\"Soft-Hard: {len(df_soft_hard)} —Ä–µ–±–µ—Ä\")\n",
        "print(f\"Profession-Soft: {len(df_profession_soft)} —Ä–µ–±–µ—Ä\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BTldsSiw1LRy",
        "outputId": "3446d3ce-f66d-4854-bc83-a15c88ac3418"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîç –ü–µ—Ä–≤—ã–π –ø—Ä–æ—Ö–æ–¥: —Å–±–æ—Ä —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1it [00:14, 14.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìä –†–∞—Å—á–µ—Ç NPMI –¥–ª—è –≥—Ä–∞—Ñ–æ–≤...\n",
            "‚úÖ –ì—Ä–∞—Ñ—ã –ø–æ—Å—Ç—Ä–æ–µ–Ω—ã:\n",
            "Soft-Soft: 4323 —Ä–µ–±–µ—Ä\n",
            "Soft-Hard: 16802 —Ä–µ–±–µ—Ä\n",
            "Profession-Soft: 1800 —Ä–µ–±–µ—Ä\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "KT4bpt7_xFZF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b266cba2-4600-4f7d-b862-1653959901b1"
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "–ó–∞–ø–∏—Å—å –≤ —Ñ–∞–π–ª df_soft_soft —É—Å–ø–µ—à–Ω–∞!\n",
            "–ó–∞–ø–∏—Å—å –≤ —Ñ–∞–π–ª df_soft_hard —É—Å–ø–µ—à–Ω–∞!\n",
            "–ó–∞–ø–∏—Å—å –≤ —Ñ–∞–π–ª df_profession_soft —É—Å–ø–µ—à–Ω–∞!\n"
          ]
        }
      ],
      "execution_count": 13,
      "source": [
        "def write_to_file(soft_soft, soft_hard,profession_soft):\n",
        "    soft_soft.to_csv('df_soft_soft', encoding='utf-8')\n",
        "    print(\"–ó–∞–ø–∏—Å—å –≤ —Ñ–∞–π–ª df_soft_soft —É—Å–ø–µ—à–Ω–∞!\")\n",
        "    soft_hard.to_csv('df_soft_hard', encoding='utf-8')\n",
        "    print(\"–ó–∞–ø–∏—Å—å –≤ —Ñ–∞–π–ª df_soft_hard —É—Å–ø–µ—à–Ω–∞!\")\n",
        "    profession_soft.to_csv('df_profession_soft',encoding='utf-8')\n",
        "    print(\"–ó–∞–ø–∏—Å—å –≤ —Ñ–∞–π–ª df_profession_soft —É—Å–ø–µ—à–Ω–∞!\")\n",
        "    #nodes.to_csv('df_nodes',encoding='utf-8')\n",
        "    #print(\"–ó–∞–ø–∏—Å—å –≤ —Ñ–∞–π–ª df_nodes —É—Å–ø–µ—à–Ω–∞!\")\n",
        "write_to_file(df_soft_soft,df_soft_hard,df_profession_soft)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "number_of_edges=100"
      ],
      "metadata": {
        "id": "ES1hDazIU32D"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "–ì—Ä–∞—Ñ–∏–∫–∏ –Ω–∏–∂–µ —Å —Ü–≤–µ—Ç–æ–º –∏ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å—é –≤–µ—Å–∞ –∏–Ω–æ–≥–¥–∞ –≤—ã–µ–±—ã–≤–∞—é—Ç—Å—è, —á—Ç–æ–±—ã –≤—Å–µ –±—ã–ª–æ –æ–∫, –º–æ–∂–Ω–æ –∑–∞–ø—É—Å—Ç–∏—Ç—å –≥—Ä–∞—Ñ–∏–∫ –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –æ–∫–Ω–µ(–≤–µ—Ä—Ö–Ω–∏–π –ø—Ä–∞–≤—ã–π —É–≥–æ–ª, —Ç—Ä–µ—Ç—å—è —Å–ø—Ä–∞–≤–∞ –∫–Ω–æ–ø–∫–∞)"
      ],
      "metadata": {
        "id": "Kgac0DMVyvSd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö\n",
        "nodes_set = set(df_soft_soft['source']).union(set(df_soft_soft['target']))\n",
        "nodes_df = pd.DataFrame({\"node\": list(nodes_set)})\n",
        "nodes_df[\"frequency\"] = nodes_df[\"node\"].map(soft_freq)\n",
        "nodes_df[\"type\"] = \"soft\"\n",
        "\n",
        "# –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è —Å–ª–∞–±—ã—Ö —Å–≤—è–∑–µ–π\n",
        "filtered_edges = df_soft_soft[df_soft_soft[\"npmi\"] > 0.2] \\\n",
        "    .sort_values(\"npmi\", ascending=False) \\\n",
        "    .head(number_of_edges)\n",
        "\n",
        "top_nodes = set(filtered_edges['source']).union(set(filtered_edges['target']))\n",
        "nodes_df = nodes_df[nodes_df['node'].isin(top_nodes)]\n",
        "\n",
        "# –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∞\n",
        "graphistry.register(api=3, protocol=\"https\", server=\"hub.graphistry.com\", personal_key_id=\"TCSI0SV3RL\", personal_key_secret=\"XYF05KFCBNK1W2RX\")\n",
        "g = graphistry.nodes(nodes_df, \"node\") \\\n",
        "    .edges(filtered_edges, \"source\", \"target\") \\\n",
        "    .bind(\n",
        "        #point_color=\"type\",\n",
        "        point_size=\"frequency\",\n",
        "        edge_weight=\"npmi\",\n",
        "        edge_title=\"co_occurrence\"\n",
        "    )\n",
        "print(\"–í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–Ø Soft-Soft –≥—Ä–∞—Ñ–∞ –ø–æ –¢–û–ü-\"+str(number_of_edges)+ \" —Å–≤—è–∑—è–º –ø–æ NPMI\")\n",
        "\n",
        "g.plot()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "id": "Ifo_BPfTT5RX",
        "outputId": "ea1e465a-a8a9-42c7-e9f9-1339ad877e3a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "–í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–Ø Soft-Soft –≥—Ä–∞—Ñ–∞ –ø–æ –¢–û–ü-100 —Å–≤—è–∑—è–º –ø–æ NPMI\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <iframe id=\"41b2851e-b92f-4582-af30-7d13d6e5acbb\" src=\"https://hub.graphistry.com/graph/graph.html?dataset=e47aadcc3a784368ac89912a038ee593&type=arrow&viztoken=bb3837ed-6379-4256-9eef-825b9e6f981e&usertag=7e8c2dc9-pygraphistry-0.41.0&splashAfter=1754560217&info=true\"\n",
              "                    allowfullscreen=\"true\" webkitallowfullscreen=\"true\" mozallowfullscreen=\"true\"\n",
              "                    oallowfullscreen=\"true\" msallowfullscreen=\"true\"\n",
              "                    style=\"width:100%; height:500px; border: 1px solid #DDD; overflow: hidden\"\n",
              "                    \n",
              "            >\n",
              "            </iframe>\n",
              "        \n",
              "            <script>\n",
              "                try {\n",
              "                  $(\"#41b2851e-b92f-4582-af30-7d13d6e5acbb\").bind('mousewheel', function(e) { e.preventDefault(); });\n",
              "                } catch (e) { console.error('exn catching scroll', e); }\n",
              "            </script>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö\n",
        "nodes_set = set(df_soft_hard['source']).union(set(df_soft_hard['target']))\n",
        "nodes_df = pd.DataFrame({\"node\": list(nodes_set)})\n",
        "\n",
        "# –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–∞ —É–∑–ª–∞ –∏ —á–∞—Å—Ç–æ—Ç—ã\n",
        "def get_node_type(node):\n",
        "    if node.startswith(\"SOFT_\"):\n",
        "        return \"soft\", soft_freq.get(node, 1)\n",
        "    return \"hard\", hard_freq.get(node, 1)\n",
        "\n",
        "nodes_df[[\"type\", \"frequency\"]] = nodes_df[\"node\"].apply(\n",
        "    lambda x: pd.Series(get_node_type(x))\n",
        ")\n",
        "\n",
        "# –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è —Å–≤—è–∑–µ–π\n",
        "filtered_edges = df_soft_hard[df_soft_hard[\"npmi\"] > 0.2] \\\n",
        "    .sort_values(\"npmi\", ascending=False) \\\n",
        "    .head(number_of_edges)\n",
        "\n",
        "top_nodes = set(filtered_edges['source']).union(set(filtered_edges['target']))\n",
        "nodes_df = nodes_df[nodes_df['node'].isin(top_nodes)]\n",
        "\n",
        "# –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∞\n",
        "g = graphistry.nodes(nodes_df, \"node\") \\\n",
        "    .edges(filtered_edges, \"source\", \"target\") \\\n",
        "    .bind(\n",
        "        point_color=\"type\",\n",
        "        point_size=\"frequency\",\n",
        "        point_title=\"node\",\n",
        "        edge_weight=\"npmi\",\n",
        "        edge_title=\"co_occurrence\"\n",
        "    )\\\n",
        "    .encode_point_color(\"type\", categorical_mapping={\n",
        "          'soft': 'blue',\n",
        "          'hard': 'orange'\n",
        "      }, default_mapping='gray')\n",
        "\n",
        "\n",
        "print(\"–í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–Ø Soft-Hard –≥—Ä–∞—Ñ–∞ –ø–æ –¢–û–ü-\"+str(number_of_edges)+ \" —Å–≤—è–∑—è–º –ø–æ NPMI\")\n",
        "g.plot()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "id": "zkhqXV_TW27p",
        "outputId": "6ef80fec-ecb0-4d73-c413-5cce161ed383"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "–í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–Ø Soft-Hard –≥—Ä–∞—Ñ–∞ –ø–æ –¢–û–ü-100 —Å–≤—è–∑—è–º –ø–æ NPMI\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <iframe id=\"ced0a8bb-5695-4c53-8c97-13cc00d87348\" src=\"https://hub.graphistry.com/graph/graph.html?dataset=e8e16aa343aa438ba084c805a7367efa&type=arrow&viztoken=bf7746c1-182a-46c2-a341-89b1ff1b5b60&usertag=7e8c2dc9-pygraphistry-0.41.0&splashAfter=1754560218&info=true\"\n",
              "                    allowfullscreen=\"true\" webkitallowfullscreen=\"true\" mozallowfullscreen=\"true\"\n",
              "                    oallowfullscreen=\"true\" msallowfullscreen=\"true\"\n",
              "                    style=\"width:100%; height:500px; border: 1px solid #DDD; overflow: hidden\"\n",
              "                    \n",
              "            >\n",
              "            </iframe>\n",
              "        \n",
              "            <script>\n",
              "                try {\n",
              "                  $(\"#ced0a8bb-5695-4c53-8c97-13cc00d87348\").bind('mousewheel', function(e) { e.preventDefault(); });\n",
              "                } catch (e) { console.error('exn catching scroll', e); }\n",
              "            </script>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1_7daCad-fLN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö\n",
        "nodes_set = set(df_profession_soft['source']).union(set(df_profession_soft['target']))\n",
        "nodes_df = pd.DataFrame({\"node\": list(nodes_set)})\n",
        "\n",
        "# –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–∞ —É–∑–ª–∞ –∏ —á–∞—Å—Ç–æ—Ç—ã\n",
        "def get_node_type(node):\n",
        "    if node in profession_freq:\n",
        "        return \"profession\", profession_freq.get(node, 1)\n",
        "    return \"soft\", soft_freq.get(node, 1)\n",
        "\n",
        "nodes_df[[\"type\", \"frequency\"]] = nodes_df[\"node\"].apply(\n",
        "    lambda x: pd.Series(get_node_type(x))\n",
        ")\n",
        "\n",
        "# –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è —Å–≤—è–∑–µ–π\n",
        "#filtered_edges = df_profession_soft[df_profession_soft[\"npmi\"] > 0.05]\n",
        "filtered_edges = df_profession_soft[df_profession_soft[\"npmi\"] > 0.2] \\\n",
        "    .sort_values(\"npmi\", ascending=False) \\\n",
        "    .head(number_of_edges)\n",
        "\n",
        "top_nodes = set(filtered_edges['source']).union(set(filtered_edges['target']))\n",
        "nodes_df = nodes_df[nodes_df['node'].isin(top_nodes)]\n",
        "# –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∞\n",
        "g = graphistry.nodes(nodes_df, \"node\") \\\n",
        "    .edges(filtered_edges, \"source\", \"target\") \\\n",
        "    .bind(\n",
        "        point_color=\"type\",\n",
        "        point_size=\"frequency\",\n",
        "        point_title=\"node\",\n",
        "        edge_weight=\"npmi\",\n",
        "        edge_title=\"co_occurrence\"\n",
        "    )\\\n",
        "    .encode_point_color(\"type\", categorical_mapping={\n",
        "          'profession': 'red',\n",
        "          'soft': 'blue'\n",
        "      }, default_mapping='gray')\n",
        "\n",
        "\n",
        "print(\"–í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–Ø Profession-Soft –≥—Ä–∞—Ñ–∞ –ø–æ –¢–û–ü-\"+str(number_of_edges)+ \" —Å–≤—è–∑—è–º –ø–æ NPMI\")\n",
        "g.plot()"
      ],
      "metadata": {
        "id": "9S9-I54b1Lnm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "outputId": "1382b89b-291f-4308-fc80-67fdcacc0711"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "–í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–Ø Profession-Soft –≥—Ä–∞—Ñ–∞ –ø–æ –¢–û–ü-100 —Å–≤—è–∑—è–º –ø–æ NPMI\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <iframe id=\"2561e404-0986-4f5f-9d10-898bc53d3dcf\" src=\"https://hub.graphistry.com/graph/graph.html?dataset=7b85c4d9ae094fb68c2f3031bcd64e6e&type=arrow&viztoken=02cc74bf-6ab1-462c-824d-3f6f6003205d&usertag=7e8c2dc9-pygraphistry-0.41.0&splashAfter=1754560220&info=true\"\n",
              "                    allowfullscreen=\"true\" webkitallowfullscreen=\"true\" mozallowfullscreen=\"true\"\n",
              "                    oallowfullscreen=\"true\" msallowfullscreen=\"true\"\n",
              "                    style=\"width:100%; height:500px; border: 1px solid #DDD; overflow: hidden\"\n",
              "                    \n",
              "            >\n",
              "            </iframe>\n",
              "        \n",
              "            <script>\n",
              "                try {\n",
              "                  $(\"#2561e404-0986-4f5f-9d10-898bc53d3dcf\").bind('mousewheel', function(e) { e.preventDefault(); });\n",
              "                } catch (e) { console.error('exn catching scroll', e); }\n",
              "            </script>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}